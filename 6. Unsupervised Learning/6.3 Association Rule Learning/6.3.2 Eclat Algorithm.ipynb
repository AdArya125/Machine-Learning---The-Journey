{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb9deab-47c1-437b-9316-ec52f487aa44",
   "metadata": {},
   "source": [
    "# 6.3.2 Eclat Algorithm\n",
    "## Introduction\n",
    "\n",
    "The Eclat (Equivalence Class Clustering and bottom-up Lattice Traversal) algorithm is a popular method for frequent itemset mining in large transactional databases. Unlike the Apriori algorithm, which uses a breadth-first search strategy, Eclat uses a depth-first search strategy to discover frequent itemsets.\n",
    "\n",
    "### Key Points:\n",
    "- **Depth-First Search**: Eclat uses a depth-first search approach, making it efficient for mining large datasets with many transactions.\n",
    "- **Intersection-based**: The algorithm relies on the intersection of transaction IDs (TID) lists to find frequent itemsets.\n",
    "- **Memory Usage**: Eclat can be more memory-intensive compared to Apriori because it requires keeping track of transaction IDs for each itemset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bddd8a-cb07-4c69-870a-ced554c50959",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "### Readings:\n",
    "- [The Eclat algorithm](https://readmedium.com/en/https:/towardsdatascience.com/the-eclat-algorithm-8ae3276d2d17)\n",
    "- [The Eclat Algorithm (pdf)](https://www.philippe-fournier-viger.com/COURSES/Pattern_mining/Eclat.pdf)\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fb571-b3d6-4b8d-a488-191faf78355b",
   "metadata": {},
   "source": [
    "## Scenarios where the Eclat Algorithm is Beneficial\n",
    "\n",
    "Eclat is particularly useful in scenarios where:\n",
    "- **Large Datasets**: The dataset contains a large number of transactions, making depth-first search more efficient.\n",
    "- **Sparse Data**: The data is sparse, meaning that there are many items but only a few transactions contain a particular item.\n",
    "- **Frequent Itemsets Needed**: The goal is to find frequent itemsets without generating candidate sets iteratively as in Apriori.\n",
    "\n",
    "## Methods for Implementing the Eclat Algorithm\n",
    "\n",
    "The Eclat algorithm can be implemented using the following steps:\n",
    "\n",
    "1. **Transform the Dataset**: Convert the transactional database into a vertical data format, where each item is associated with a list of transaction IDs.\n",
    "2. **Depth-First Search**: Perform a depth-first search on the vertical data to find frequent itemsets by intersecting TID lists.\n",
    "3. **Pruning**: Use support thresholds to prune infrequent itemsets and optimize the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9d2147-3ebd-4c56-a460-aeb609134728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c46cb43-9010-43f1-8af9-1a0099dfa942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38765, 3)\n",
      "   Member_number        Date   itemDescription\n",
      "0           1808  21-07-2015    tropical fruit\n",
      "1           2552  05-01-2015        whole milk\n",
      "2           2300  19-09-2015         pip fruit\n",
      "3           1187  12-12-2015  other vegetables\n",
      "4           3037  01-02-2015        whole milk\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "groceries = pd.read_csv(\"Groceries_dataset.csv\")\n",
    "print(groceries.shape)\n",
    "print(groceries.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba510756-50cf-4f40-b034-4ac0a23b0f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the transactions as a list of lists\n",
    "all_transactions = [transaction[1]['itemDescription'].tolist() for transaction in list(groceries.groupby(['Member_number', 'Date']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b470d5-801d-4001-ad8c-2b7e5c5fe36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vertical data format\n",
    "vertical_format = defaultdict(set)\n",
    "for tid, transaction in enumerate(all_transactions):\n",
    "    for item in transaction:\n",
    "        vertical_format[item].add(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "059097b4-be67-4be8-893c-a863c4aca253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find frequent itemsets using Eclat\n",
    "def eclat(prefix, items, min_support, vertical_data):\n",
    "    if len(items) == 0:\n",
    "        return []\n",
    "    \n",
    "    itemsets = []\n",
    "    while items:\n",
    "        item = items.pop()\n",
    "        new_prefix = prefix + [item]\n",
    "        itemsets.append((new_prefix, len(vertical_data[item])))\n",
    "        \n",
    "        new_items = []\n",
    "        new_vertical_data = {}\n",
    "        for other_item in items:\n",
    "            intersection = vertical_data[item] & vertical_data[other_item]\n",
    "            if len(intersection) >= min_support:\n",
    "                new_items.append(other_item)\n",
    "                new_vertical_data[other_item] = intersection\n",
    "        \n",
    "        itemsets.extend(eclat(new_prefix, new_items, min_support, new_vertical_data))\n",
    "    \n",
    "    return itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9270ad-7e14-47f2-8c5d-36fc532515ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "(['pork', 'other vegetables'], 59)\n",
      "(['pork', 'rolls/buns'], 51)\n",
      "(['pork', 'whole milk'], 75)\n",
      "(['fruit/vegetable juice', 'rolls/buns'], 56)\n",
      "(['fruit/vegetable juice', 'whole milk'], 66)\n",
      "(['brown bread', 'rolls/buns'], 50)\n",
      "(['brown bread', 'whole milk'], 67)\n",
      "(['citrus fruit', 'other vegetables'], 72)\n",
      "(['citrus fruit', 'rolls/buns'], 70)\n",
      "(['citrus fruit', 'soda'], 56)\n",
      "(['citrus fruit', 'yogurt'], 69)\n",
      "(['citrus fruit', 'whole milk'], 107)\n",
      "(['coffee', 'whole milk'], 57)\n",
      "(['newspapers', 'other vegetables'], 55)\n",
      "(['newspapers', 'whole milk'], 84)\n",
      "(['domestic eggs', 'other vegetables'], 53)\n",
      "(['domestic eggs', 'rolls/buns'], 51)\n",
      "(['domestic eggs', 'whole milk'], 79)\n",
      "(['bottled beer', 'other vegetables'], 70)\n",
      "(['bottled beer', 'rolls/buns'], 60)\n",
      "(['bottled beer', 'yogurt'], 51)\n",
      "(['bottled beer', 'whole milk'], 107)\n",
      "(['bottled beer', 'sausage'], 50)\n",
      "(['chicken', 'whole milk'], 51)\n",
      "(['bottled water', 'root vegetables'], 52)\n",
      "(['bottled water', 'tropical fruit'], 53)\n",
      "(['bottled water', 'other vegetables'], 82)\n",
      "(['bottled water', 'rolls/buns'], 70)\n",
      "(['bottled water', 'soda'], 72)\n",
      "(['bottled water', 'yogurt'], 57)\n",
      "(['bottled water', 'whole milk'], 107)\n",
      "(['margarine', 'whole milk'], 61)\n",
      "(['shopping bags', 'root vegetables'], 50)\n",
      "(['shopping bags', 'other vegetables'], 74)\n",
      "(['shopping bags', 'rolls/buns'], 71)\n",
      "(['shopping bags', 'soda'], 66)\n",
      "(['shopping bags', 'yogurt'], 53)\n",
      "(['shopping bags', 'whole milk'], 95)\n",
      "(['pip fruit', 'other vegetables'], 74)\n",
      "(['pip fruit', 'rolls/buns'], 74)\n",
      "(['pip fruit', 'soda'], 59)\n",
      "(['pip fruit', 'yogurt'], 54)\n",
      "(['pip fruit', 'whole milk'], 99)\n",
      "(['root vegetables', 'tropical fruit'], 55)\n",
      "(['root vegetables', 'other vegetables'], 79)\n",
      "(['root vegetables', 'rolls/buns'], 86)\n",
      "(['root vegetables', 'soda'], 79)\n",
      "(['root vegetables', 'yogurt'], 64)\n",
      "(['root vegetables', 'whole milk'], 113)\n",
      "(['root vegetables', 'sausage'], 50)\n",
      "(['tropical fruit', 'other vegetables'], 94)\n",
      "(['tropical fruit', 'rolls/buns'], 91)\n",
      "(['tropical fruit', 'soda'], 81)\n",
      "(['tropical fruit', 'yogurt'], 78)\n",
      "(['tropical fruit', 'whole milk'], 123)\n",
      "(['butter', 'whole milk'], 70)\n",
      "(['other vegetables', 'whipped/sour cream'], 62)\n",
      "(['other vegetables', 'rolls/buns'], 158)\n",
      "(['other vegetables', 'curd'], 53)\n",
      "(['other vegetables', 'frankfurter'], 77)\n",
      "(['other vegetables', 'soda'], 145)\n",
      "(['other vegetables', 'canned beer'], 60)\n",
      "(['other vegetables', 'pastry'], 55)\n",
      "(['other vegetables', 'yogurt'], 121)\n",
      "(['other vegetables', 'whole milk'], 222)\n",
      "(['other vegetables', 'sausage'], 90)\n",
      "(['frozen vegetables', 'whole milk'], 57)\n",
      "(['whipped/sour cream', 'soda'], 51)\n",
      "(['whipped/sour cream', 'whole milk'], 69)\n",
      "(['beef', 'whole milk'], 70)\n",
      "(['rolls/buns', 'frankfurter'], 55)\n",
      "(['rolls/buns', 'soda'], 121)\n",
      "(['rolls/buns', 'canned beer'], 63)\n",
      "(['rolls/buns', 'pastry'], 59)\n",
      "(['rolls/buns', 'yogurt'], 117)\n",
      "(['rolls/buns', 'whole milk'], 209)\n",
      "(['rolls/buns', 'sausage'], 80)\n",
      "(['curd', 'whole milk'], 62)\n",
      "(['frankfurter', 'whole milk'], 79)\n",
      "(['soda', 'pastry'], 61)\n",
      "(['soda', 'yogurt'], 87)\n",
      "(['soda', 'whole milk'], 174)\n",
      "(['soda', 'sausage'], 89)\n",
      "(['canned beer', 'yogurt'], 58)\n",
      "(['canned beer', 'whole milk'], 90)\n",
      "(['pastry', 'yogurt'], 54)\n",
      "(['pastry', 'whole milk'], 97)\n",
      "(['yogurt', 'whole milk'], 167)\n",
      "(['yogurt', 'sausage'], 86)\n",
      "(['whole milk', 'sausage'], 134)\n"
     ]
    }
   ],
   "source": [
    "# Set minimum support\n",
    "min_support = 50\n",
    "\n",
    "# Run Eclat algorithm\n",
    "frequent_itemsets = eclat([], list(vertical_format.keys()), min_support, vertical_format)\n",
    "frequent_itemsets = [itemset for itemset in frequent_itemsets if len(itemset[0]) > 1]\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "for itemset in frequent_itemsets:\n",
    "    print(itemset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0247b2-a649-40f1-b554-34b71ae0dac4",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The Eclat algorithm is an efficient method for mining frequent itemsets in large and sparse transactional databases. By using a depth-first search strategy and intersection of transaction ID lists, Eclat can quickly identify frequent itemsets without the need for iterative candidate generation. This makes it particularly useful for applications requiring frequent pattern discovery in large datasets, such as market basket analysis and web usage mining. The provided Python implementation demonstrates how to apply the Eclat algorithm to a sample dataset, showcasing the identification of frequent itemsets based on a specified minimum support threshold.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
