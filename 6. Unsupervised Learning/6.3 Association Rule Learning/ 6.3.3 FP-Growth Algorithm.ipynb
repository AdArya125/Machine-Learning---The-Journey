{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdacd423-1210-4e6b-bbdd-3dc1cfd59d89",
   "metadata": {},
   "source": [
    "# 6.3.3 FP-Growth Algorithm\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The FP-Growth (Frequent Pattern Growth) algorithm is an efficient and scalable method for mining frequent itemsets from large datasets. Unlike the Apriori algorithm, which generates candidate itemsets and tests them against the database, FP-Growth uses a compact data structure called the FP-Tree (Frequent Pattern Tree) to represent the dataset. This tree allows the algorithm to mine frequent patterns without candidate generation, making it much faster and more efficient, especially for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4bffb-b71e-42b8-878c-482286ededed",
   "metadata": {},
   "source": [
    "\n",
    "### Algorithm\n",
    "\n",
    "1. **Construct the FP-Tree**:\n",
    "    - Scan the database to find the support count of each item and discard infrequent items.\n",
    "    - Sort frequent items in descending order of their support counts.\n",
    "    - Build the FP-Tree by reading the transactions again and inserting items into the tree according to the sorted order.\n",
    "\n",
    "2. **Mine the FP-Tree**:\n",
    "    - Starting from the frequent items in the header table, construct conditional FP-Trees.\n",
    "    - Recursively mine these conditional trees to extract frequent patterns.\n",
    "    - Combine the frequent patterns generated from each conditional tree to form the complete set of frequet patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eef3ce-0333-4b23-93f5-24bde4cea5dd",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "### Readings:\n",
    "- [FP-Growth Algorithm](https://athena.ecs.csus.edu/~mei/associationcw/FpGrowth.html)\n",
    "- [FP-Growth Algorithm](https://readmedium.com/en/https:/ai.plainenglish.io/fp-growth-algorithm-3f0e511231c7)\n",
    "- [Hands-on Tutorials - The FP Growth algorithm](https://readmedium.com/en/https:/towardsdatascience.com/the-fp-growth-algorithm-1ffa20e839b8)\n",
    "- [Association Rule(Apriori and FP-Growth Algorithms) with Practical Implementation](https://medium.com/machine-learning-researcher/association-rule-apriori-and-eclat-algorithm-4e963fa972a4)\n",
    "- [Pros and Cons of Apriori, Eclat, and FP-growth](https://readmedium.com/en/https:/medium.com/@tarek.tm/mastering-association-rule-learning-pros-and-cons-of-apriori-eclat-and-fp-growth-530ff46ed1d9)\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f58a6e-421e-45b7-8e69-d64012b334c2",
   "metadata": {},
   "source": [
    "### Key Features and Benefits\n",
    "\n",
    "- **Efficiency**: FP-Growth is faster and more memory-efficient than Apriori because it reduces the number of database scans and avoids candidate generation.\n",
    "- **Scalability**: It can handle large datasets efficiently.\n",
    "- **Compact Representation**: The FP-Tree structure provides a compact representation of the dataset, allowing for efficient mining of requent patterns.\n",
    "\n",
    "### Scenarios and Use Cases\n",
    "\n",
    "FP-Growth is particularly beneficial in scenarios where:\n",
    "- The dataset is large, and traditional algorithms like Apriori become inefficient.\n",
    "- There is a need to find frequent itemsets quickly and efficiently.\n",
    "- The dataset has a high level of item redundancy, as the FP-Tree can compress theciation rules in various domains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad453f96-8b59-4881-9e6f-fdd7cf400048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37a8c21-4b57-4936-b218-0d3f0c174349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38765, 3)\n",
      "   Member_number        Date   itemDescription\n",
      "0           1808  21-07-2015    tropical fruit\n",
      "1           2552  05-01-2015        whole milk\n",
      "2           2300  19-09-2015         pip fruit\n",
      "3           1187  12-12-2015  other vegetables\n",
      "4           3037  01-02-2015        whole milk\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "groceries = pd.read_csv(\"Groceries_dataset.csv\")\n",
    "print(groceries.shape)\n",
    "print(groceries.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c099a348-707f-4d6d-888e-143cda8930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the transactions as a list of lists\n",
    "all_transactions = [transaction[1]['itemDescription'].tolist() for transaction in list(groceries.groupby(['Member_number', 'Date']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ad40e8-6a93-4af9-9cb0-74a699d50688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data using TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(all_transactions).transform(all_transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a0fc79-ebb3-4ec4-b3a9-271c13c55e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "      support                     itemsets\n",
      "0    0.157923                 (whole milk)\n",
      "1    0.085879                     (yogurt)\n",
      "2    0.060349                    (sausage)\n",
      "3    0.009490        (semi-finished bread)\n",
      "4    0.051728                     (pastry)\n",
      "..        ...                          ...\n",
      "121  0.007151   (whole milk, bottled beer)\n",
      "122  0.005280  (domestic eggs, whole milk)\n",
      "123  0.005614     (whole milk, newspapers)\n",
      "124  0.007151   (citrus fruit, whole milk)\n",
      "125  0.005012           (pork, whole milk)\n",
      "\n",
      "[126 rows x 2 columns]\n",
      "\n",
      "Association Rules:\n",
      "           antecedents         consequents  antecedent support  \\\n",
      "0             (yogurt)        (whole milk)            0.085879   \n",
      "1            (sausage)        (whole milk)            0.060349   \n",
      "2             (pastry)        (whole milk)            0.051728   \n",
      "3        (canned beer)        (whole milk)            0.046916   \n",
      "4               (soda)        (whole milk)            0.097106   \n",
      "5        (frankfurter)        (whole milk)            0.037760   \n",
      "6        (frankfurter)  (other vegetables)            0.037760   \n",
      "7         (rolls/buns)        (whole milk)            0.110005   \n",
      "8   (other vegetables)        (whole milk)            0.122101   \n",
      "9     (tropical fruit)        (whole milk)            0.067767   \n",
      "10   (root vegetables)        (whole milk)            0.069572   \n",
      "11         (pip fruit)        (whole milk)            0.049054   \n",
      "12     (shopping bags)        (whole milk)            0.047584   \n",
      "13     (bottled water)        (whole milk)            0.060683   \n",
      "14      (bottled beer)        (whole milk)            0.045312   \n",
      "15     (domestic eggs)        (whole milk)            0.037091   \n",
      "16        (newspapers)        (whole milk)            0.038896   \n",
      "17      (citrus fruit)        (whole milk)            0.053131   \n",
      "18              (pork)        (whole milk)            0.037091   \n",
      "\n",
      "    consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "0             0.157923  0.011161    0.129961  0.822940 -0.002401    0.967861   \n",
      "1             0.157923  0.008955    0.148394  0.939663 -0.000575    0.988811   \n",
      "2             0.157923  0.006483    0.125323  0.793571 -0.001686    0.962729   \n",
      "3             0.157923  0.006015    0.128205  0.811821 -0.001394    0.965912   \n",
      "4             0.157923  0.011629    0.119752  0.758296 -0.003707    0.956636   \n",
      "5             0.157923  0.005280    0.139823  0.885388 -0.000683    0.978958   \n",
      "6             0.122101  0.005146    0.136283  1.116150  0.000536    1.016420   \n",
      "7             0.157923  0.013968    0.126974  0.804028 -0.003404    0.964550   \n",
      "8             0.157923  0.014837    0.121511  0.769430 -0.004446    0.958551   \n",
      "9             0.157923  0.008220    0.121302  0.768108 -0.002482    0.958323   \n",
      "10            0.157923  0.007552    0.108549  0.687357 -0.003435    0.944615   \n",
      "11            0.157923  0.006616    0.134877  0.854071 -0.001130    0.973362   \n",
      "12            0.157923  0.006349    0.133427  0.844887 -0.001166    0.971732   \n",
      "13            0.157923  0.007151    0.117841  0.746196 -0.002432    0.954564   \n",
      "14            0.157923  0.007151    0.157817  0.999330 -0.000005    0.999874   \n",
      "15            0.157923  0.005280    0.142342  0.901341 -0.000578    0.981834   \n",
      "16            0.157923  0.005614    0.144330  0.913926 -0.000529    0.984114   \n",
      "17            0.157923  0.007151    0.134591  0.852259 -0.001240    0.973040   \n",
      "18            0.157923  0.005012    0.135135  0.855703 -0.000845    0.973652   \n",
      "\n",
      "    zhangs_metric  \n",
      "0       -0.190525  \n",
      "1       -0.063965  \n",
      "2       -0.215266  \n",
      "3       -0.195630  \n",
      "4       -0.260917  \n",
      "5       -0.118576  \n",
      "6        0.108146  \n",
      "7       -0.214986  \n",
      "8       -0.254477  \n",
      "9       -0.244626  \n",
      "10      -0.328344  \n",
      "11      -0.152310  \n",
      "12      -0.161610  \n",
      "13      -0.265842  \n",
      "14      -0.000702  \n",
      "15      -0.102072  \n",
      "16      -0.089246  \n",
      "17      -0.154748  \n",
      "18      -0.149027  \n"
     ]
    }
   ],
   "source": [
    "# Generate frequent itemsets using FP-Growth\n",
    "frequent_itemsets = fpgrowth(df, min_support=0.005, use_colnames=True)\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc3b50-d372-4747-8f16-0de7690d69f0",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion\n",
    "\n",
    "The FP-Growth algorithm offers a powerful and efficient approach for frequent itemset mining, making it suitable for large-scale data mining applications. Its ability to handle large datasets with high efficiency and scalability makes it a valuable tool for discovering frequent patterns and generating association rules in various domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
