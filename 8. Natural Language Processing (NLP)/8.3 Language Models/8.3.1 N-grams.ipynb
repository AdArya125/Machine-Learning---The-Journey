{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8234d6-b8e9-4b13-86d9-21681b5401d7",
   "metadata": {},
   "source": [
    "\n",
    "## 8.3.1 N-grams\r\n",
    "\r\n",
    "### Explanation of N-gram Models\r\n",
    "\r\n",
    "N-grams are a fundamental concept in Natural Language Processing (NLP) used to model the structure of text. An N-gram is a contiguous sequence of \\( N \\) items from a given sample of text or speech. In the context of text, these items can be characters, words, or even sentences. \r\n",
    "\r\n",
    "For example:\r\n",
    "- Unigram (1-gram): \"The\"\r\n",
    "- Bigram (2-gram): \"The cat\"\r\n",
    "- Trigram (3-gram): \"The cat sat\"\r\n",
    "\r\n",
    "N-gram models are used to predict the next item in such sequences based on the previous \\( N-1 \\) items. These models are simple yet powerful for tasks such as text generation, machine translation, and speech recognition.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c683c58-880a-4817-b9f8-3d75bc7250a2",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "### Readings:\n",
    "- [What are N-Grams?](https://kavita-ganesan.com/what-are-n-grams/)\n",
    "- [What Are N-Grams and How to Implement Them in Python?](https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/)\n",
    "- [Exploring N-gram Models in Natural Language Processing](https://readmedium.com/en/https:/medium.com/@evertongomede/exploring-n-gram-models-in-natural-language-processing-bf5852b32050)\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f236be-af4f-40cd-9d5f-f4f93e4d1fae",
   "metadata": {},
   "source": [
    "### Benefits and Scenarios for Using N-grams\n",
    "\n",
    "N-grams have several benefits and are used in various NLP scenarios:\n",
    "\n",
    "- **Simplicity**: N-gram models are relatively easy to understand and implement.\n",
    "- **Text Generation**: N-grams can be used to generate new text by predicting the next word in a sequence.\n",
    "- **Language Modeling**: They are used in building language models that can predict the probability of a sequence of words.\n",
    "- **Feature Extraction**: N-grams serve as features in text classification and sentiment analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463b3b68-8cf8-424c-a09a-7a976f5c792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love: 1\n",
      "machine: 3\n",
      "learning: 4\n",
      "love machine: 1\n",
      "machine learning: 3\n",
      "is: 1\n",
      "amazing: 1\n",
      "learning is: 1\n",
      "is amazing: 1\n",
      "am: 1\n",
      "new: 1\n",
      "techniques: 1\n",
      "in: 1\n",
      "am learning: 1\n",
      "learning new: 1\n",
      "new techniques: 1\n",
      "techniques in: 1\n",
      "in machine: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "documents = [\n",
    "    \"I love machine learning.\",\n",
    "    \"Machine learning is amazing.\",\n",
    "    \"I am learning new techniques in machine learning.\"\n",
    "]\n",
    "\n",
    "# Create a CountVectorizer with n-gram range (e.g., bigrams)\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (n-grams)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Sum up the occurrences of each n-gram\n",
    "sum_words = X.sum(axis=0)\n",
    "\n",
    "# Create a dictionary of n-grams and their counts\n",
    "ngram_counts = {word: sum_words[0, idx] for word, idx in vectorizer.vocabulary_.items()}\n",
    "\n",
    "# Display the n-grams and their counts\n",
    "for ngram, count in ngram_counts.items():\n",
    "    print(f\"{ngram}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a48f4-7eca-4903-8fe4-fc7cfa3be8bb",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "### Making a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0181021b-9f1b-4639-8a87-df781985fc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   at the  barked at  brown dog  brown fox  cat chased  cat jumped  cat sat  \\\n",
      "0       0          0          0          1           0           0        0   \n",
      "1       0          0          0          0           0           0        1   \n",
      "2       1          1          0          0           0           0        0   \n",
      "3       0          0          0          1           0           0        0   \n",
      "4       0          0          0          0           1           0        0   \n",
      "5       0          0          0          0           0           0        0   \n",
      "6       0          0          0          0           0           0        0   \n",
      "7       0          0          0          0           0           1        0   \n",
      "8       0          0          1          0           0           0        0   \n",
      "9       0          0          0          0           0           0        0   \n",
      "\n",
      "   chased the  dog barked  dog chased  ...  ran away  sat on  the cat  \\\n",
      "0           0           0           0  ...         0       0        0   \n",
      "1           0           0           0  ...         0       1        1   \n",
      "2           0           1           0  ...         0       0        0   \n",
      "3           0           0           0  ...         0       0        0   \n",
      "4           1           0           0  ...         0       0        1   \n",
      "5           1           0           1  ...         0       0        1   \n",
      "6           0           0           0  ...         1       0        0   \n",
      "7           0           0           0  ...         0       0        0   \n",
      "8           0           0           0  ...         0       0        0   \n",
      "9           0           0           0  ...         0       0        0   \n",
      "\n",
      "   the dog  the lazy  the mailman  the mat  the mouse  the quick  the sun  \n",
      "0        0         1            0        0          0          1        0  \n",
      "1        0         0            0        1          0          0        0  \n",
      "2        1         0            1        0          0          0        0  \n",
      "3        0         0            0        0          0          1        0  \n",
      "4        0         0            0        0          1          0        0  \n",
      "5        1         0            0        0          0          0        0  \n",
      "6        0         0            0        0          1          0        0  \n",
      "7        0         1            0        0          0          1        0  \n",
      "8        0         0            0        0          0          1        0  \n",
      "9        0         1            0        0          0          0        1  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog barked at the mailman\",\n",
    "    \"The quick brown fox\",\n",
    "    \"The cat chased the mouse\",\n",
    "    \"The dog chased the cat\",\n",
    "    \"The mouse ran away\",\n",
    "    \"The quick cat jumped over the lazy dog\",\n",
    "    \"The quick brown dog\",\n",
    "    \"The lazy dog lay in the sun\"\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer for bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Create a DataFrame to view the bigrams and their frequencies\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6a259-f400-4e11-a512-a794a7debbe8",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "N-gram models provide a foundational approach to understanding and generating text based on contiguous sequences of items. Despite their simplicity, they are widely used in various NLP applications and serve as a basis for more complex models. Implementing N-grams using libraries like `sklearn` allows for efficient extraction and analysis of these sequences in text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
