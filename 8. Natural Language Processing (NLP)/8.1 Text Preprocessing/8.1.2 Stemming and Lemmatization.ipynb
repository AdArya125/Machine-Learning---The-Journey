{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1191bd1-bd3e-4455-ac22-88326409f8b2",
   "metadata": {},
   "source": [
    "# 8.1.2 Stemming and Lemmatization\r\n",
    "\r\n",
    "## Explanation of Stemming and Lemmatization\r\n",
    "\r\n",
    "**Stemming** and **lemmatization** are text normalization techniques used in natural language processing (NLP) to reduce words to their base or root forms.\r\n",
    "\r\n",
    "- **Stemming** involves trimming or chopping off prefixes or suffixes from words to get their root form. This process may result in words that are not actual dictionary words. For example, \"running\" may be stemmed to \"run.\"\r\n",
    "\r\n",
    "- **Lemmatization** involves reducing words to their base or dictionary form using morphological analysis. Unlike stemming, lemmatization considers the context and meaning of the word, resulting in more accurate base forms. For example, \"running\" is lemmatized to \"run.\"\r\n",
    "\r\n",
    "## Differences between Stemming and Lemmatization\r\n",
    "\r\n",
    "- **Accuracy**: Lemmatization provides more accurate base forms by considering the word's meaning and context, while stemming is a more heuristic approach that may produce less accurate results.\r\n",
    "- **Output**: Stemming may produce non-dictionary words, whereas lemmatization always produces valid words.\r\n",
    "- **Complexity**: Lemmatization is computationally more intensive and requires a more complex algorithm compared to the simpler stemming process.\r\n",
    "\r\n",
    "## Methods for Implementing Stemming and Lemmatization\r\n",
    "\r\n",
    "### Stemming\r\n",
    "\r\n",
    "1. **Porter Stemmer**\r\n",
    "\r\n",
    "   **Example**: \r\n",
    "   - \"running\" --> \"run\"\r\n",
    "   - \"easily\" --> \"easili\" (may not be a real word)\r\n",
    "\r\n",
    "2. **Snowball Stemmer**\r\n",
    "\r\n",
    "   **Example**:\r\n",
    "   - \"running\" --> \"run\"\r\n",
    "   - \"fairly\" --> \"fair\"\r\n",
    "\r\n",
    "3. **Lancaster Stemmer**\r\n",
    "\r\n",
    "   **Example**:\r\n",
    "   - \"running\" --> \"run\"\r\n",
    "   - \"easily\" --> \"eas\" (overly simplified)\r\n",
    "\r\n",
    "### Lemmatization\r\n",
    "\r\n",
    "1. **WordNet Lemmatizer**\r\n",
    "\r\n",
    "   **Example**:\r\n",
    "   - \"running\" --> \"run\"\r\n",
    "   - \"easily\" --> \"easily\" (unchanged if no valid lemma)\r\n",
    "\r\n",
    "2. **spaCy Lemmatizer**\r\n",
    "\r\n",
    "   **Example**:\r\n",
    "   - \"running\" --> \"run\"\r\n",
    "   - \"fairly\" --> \"fair\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fa1bd-5616-45d9-87d8-3ae72d314dee",
   "metadata": {},
   "source": [
    "These methods can be implemented using libraries like NLTK, spaCy, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044fc088-e30b-41b1-8cba-0d5d691ba595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3adbe3-f3df-43ea-a640-949c12f8633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data files\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('wordnet')  # For lemmatization\n",
    "nltk.download('averaged_perceptron_tagger')  # For POS tagging\n",
    "nltk.download('omw-1.4')  # For lemmatization with different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62259dc7-635c-44bf-8a82-f2f1bf2037b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The runners are running faster than the other runners\n",
      "Porter Stemmer: ['the', 'runner', 'are', 'run', 'faster', 'than', 'the', 'other', 'runner']\n",
      "Snowball Stemmer: ['the', 'runner', 'are', 'run', 'faster', 'than', 'the', 'other', 'runner']\n",
      "Lancaster Stemmer: ['the', 'run', 'ar', 'run', 'fast', 'than', 'the', 'oth', 'run']\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"The runners are running faster than the other runners\"\n",
    "\n",
    "# Stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Porter Stemmer:\", [porter_stemmer.stem(word) for word in text.split()])\n",
    "print(\"Snowball Stemmer:\", [snowball_stemmer.stem(word) for word in text.split()])\n",
    "print(\"Lancaster Stemmer:\", [lancaster_stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9880d9ab-117c-4197-a45c-c84f01815ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Text: ['The', 'runner', 'be', 'run', 'faster', 'than', 'the', 'other', 'runner']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "pos_tags = nltk.pos_tag(text_tokens)\n",
    "lemmatized_text = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
    "\n",
    "print(\"Lemmatized Text:\", lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c217adc-9d96-4744-8571-8fddaab64d6f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Stemming and lemmatization are essential techniques in the preprocessing pipeline of natural language processing (NLP). \n",
    "- **Stemming** simplifies words by cutting off derivational affixes, which can help in standardizing words to a common base form but may result in words that are not found in dictionaries.\n",
    "\n",
    "- **Lemmatization** provides a more refined approach by reducing words to their base or dictionary form, considering their part of speech, which ensures that the output is a valid word and maintains semantic meaning.\n",
    "\n",
    "Using these techniques effectively can significantly impact the performance of NLP models. Stemming is often used in applications where speed is more critical than precision, such as in search engines and information retrieval systems. Lemmatization, with its more accurate output, is preferred in scenarios requiring a deep understanding of text, such as sentiment analysis and text classification.\n",
    "\n",
    "By integrating stemming and lemmatization into text preprocessing, you can improve the quality and efficiency of text analysis, leading to better insights and more robust NLP applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
